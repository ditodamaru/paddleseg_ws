batch_size: 4
iters: 1000 #80000

train_dataset:
  type: Dataset
  dataset_root: data/custom_dataset_size_plz_0
  train_path: data/custom_dataset_size_plz_0/train.txt
  num_classes: 4
  transforms:
    - type: ResizeStepScaling
      min_scale_factor: 0.5
      max_scale_factor: 2.0
      scale_step_size: 0.25
    - type: RandomPaddingCrop
      crop_size: [896, 896]
    - type: RandomHorizontalFlip
    - type: RandomDistort
      brightness_range: 0.4
      contrast_range: 0.4
      saturation_range: 0.4
    - type: Normalize
  mode: train

val_dataset:  
  type: Dataset 
  dataset_root: data/custom_dataset_size_plz_0
  val_path: data/custom_dataset_size_plz_0/val.txt  
  num_classes: 4 
  mode: val 
  transforms: 
    - type: Normalize
  
optimizer:
  type: sgd
  momentum: 0.9
  weight_decay: 0.0005

lr_scheduler:
  type: PolynomialDecay
  learning_rate: 0.01
  end_lr: 0
  power: 0.9

loss:
  types:
    - type: CrossEntropyLoss
  coef: [1]